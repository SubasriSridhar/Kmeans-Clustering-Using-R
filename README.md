K-Means is an Unsupervised clustering technique which groups the similar objects in a dataset into one cluster and dissimilar object will belong to another cluster. In Kmeans clustering, K denotes the number of clusters in a dataset and should be known before clustering. From the given data we can clearly see that there are 3 species, so there are 3 clusters. But in general, the best optimal way to find a value of K is to try different values for it, starting from 1,2,3 and so on and compare the total variation with each K value to see if the current K value is better than the previous value. On increasing the K value, the total variation will reduce and shrink to ‘0’ when K is closer to the size of data. However, if we plot the value of variation across K, at one point the reduction will be huge and then variation will not go down further. This graph will look like the figure 1. From this we can pick K, the ‘Elbow’ point.  After knowing the value of K, random k data points are marked and distance between each point and the random points is measured. This is repeated until the points in the cluster do not change further. As the clustering technique selects data points in random to cluster, the centroid is likely to change every time. 
Taking the given Iris dataset as an example, it contains 150 observations of Iris flower with 4 attributes about length and width of Sepal and Petal and 3 different species of IRIS flower namely Iris-Setosa, Iris-Versicolor, Iris-Virginia. This species count is the number of cluster (K). From the given set of data, Kmeans groups the cluster (i.e. species) based on the length and width of Sepal and Petal.
The first step is to find out the value of ‘K’. Here we know the value of K is 3, but the way to find the number of clusters is decided by starting from 2,3,4 and so on. By the end all the Kmeans averages the sum of squared distance from the centre point and plots it across the Number of clusters. In the Elbow plot, the variation is drastic till the K value reaches 3 after which the variation in graph is steady. The Elbow point takes the K value.

Secondly, the random points are plotted to figure out the actual centroid by calculating the mean. This is repeated until no further change made in the cluster and the best is decided based on the mean. Here the distance between each point and the centroid is calculated based on Euclidean Distance formula 
Distance = √(x2-x1)2 +(y2-y1)2
The average is calculated for every random point (Centroid). On every iteration, new random points are plotted, and the iteration is repeated until there is no further change in the data points in the cluster, so that the solution is converged. 
The Kmeans cluster varies when compared to the manual clustering.  To identify the best cluster, on every execution Kmeans keeps track of total variations within the cluster and compares with each clustering output to find out the best.  The problem is that k-means picks the cluster centre at random choice that is nearest to a point, not the centre that is similar to human eyes. So, the output shown varies when running the Kmeans implementation multiple times. 
